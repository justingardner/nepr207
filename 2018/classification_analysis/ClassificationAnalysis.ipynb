{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will perform classification analysis on data from the NEPR207 2018 datasets.\n",
    "\n",
    "Note from dan:\n",
    "\n",
    "\n",
    "In each folder there are now several files:\n",
    "\n",
    "roi_instances.mat\n",
    "roi_labels.mat\n",
    "\n",
    "where roi = lV1, rV1\n",
    "\n",
    "instances is a matrix, time bin * trial * voxel\n",
    "cond is the condition labels for each trial\n",
    "\n",
    "I set it up so we could do more time bins if anybody in the class decides they want that, for now it's just the average response 3-7.5 s after stimulus onset, which should work fine for most groups.\n",
    "\n",
    "Responses are percentages relative to 1 so you probably want to subtract 1 or z-score before doing classification.\n",
    "\n",
    "368/369/370 all have two conditions (attend left/right or stimulus rotated left/right) group 371 has three conditions (task difficulty = 1/2/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy,pandas\n",
    "import sklearn\n",
    "\n",
    "subcodes=['s036820180521','s036920180521','s037020180521','s037120180521']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subcode):\n",
    "    lV1_instances=scipy.io.loadmat(os.path.join('..',subcode,'lV1_instances.mat'))['data'][0,:,:]\n",
    "    labels=scipy.io.loadmat(os.path.join('..',subcode,'lV1_labels.mat'))['cond'][:,0]\n",
    "    rV1_instances=scipy.io.loadmat(os.path.join('..',subcode,'rV1_instances.mat'))['data'][0,:,:]\n",
    "\n",
    "    instances=numpy.hstack((lV1_instances,rV1_instances))\n",
    "    assert instances.shape[0]==labels.shape[0]\n",
    "    return(labels,instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to predict condition from V1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(labels,instances,shuffle=False,\n",
    "                   cv=None,clf=None):\n",
    "\n",
    "    if cv is None:\n",
    "        cv=sklearn.model_selection.KFold(n_splits=4,shuffle=True,random_state=0)\n",
    "\n",
    "    if clf is None:\n",
    "        clf=sklearn.svm.LinearSVC()\n",
    "    predicted_labels=numpy.zeros(labels.shape)\n",
    "    scaler=sklearn.preprocessing.StandardScaler()\n",
    "    labels_copy=labels.copy()  # to prevent shuffle from affecting original variable\n",
    "\n",
    "    for train,test in cv.split(instances):\n",
    "        if shuffle:\n",
    "            numpy.random.shuffle(labels_copy)\n",
    "        train_X,test_X=instances[train,:],instances[test,:]\n",
    "        train_Y,test_Y=labels_copy[train],labels_copy[test]\n",
    "        train_X=scaler.fit_transform(train_X)\n",
    "        test_X=scaler.transform(test_X)\n",
    "        clf.fit(train_X,train_Y)\n",
    "        predicted_labels[test]=clf.predict(test_X)\n",
    "    return(predicted_labels)\n",
    "\n",
    "def print_metrics(labels,predicted_labels):\n",
    "    print('Confusion matrix:')\n",
    "    print(sklearn.metrics.confusion_matrix(labels,predicted_labels))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(labels,predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for subcode  s036820180521\n",
      "Confusion matrix:\n",
      "[[67  6]\n",
      " [ 3 72]]\n",
      "Accuracy: 0.9391891891891891\n",
      "Mean shuffled accuracy (10 runs): 0.514\n",
      "\n",
      "running for subcode  s036920180521\n",
      "Confusion matrix:\n",
      "[[37 14]\n",
      " [14 43]]\n",
      "Accuracy: 0.7407407407407407\n",
      "Mean shuffled accuracy (10 runs): 0.507\n",
      "\n",
      "running for subcode  s037020180521\n",
      "Confusion matrix:\n",
      "[[29 16]\n",
      " [12 31]]\n",
      "Accuracy: 0.6818181818181818\n",
      "Mean shuffled accuracy (10 runs): 0.518\n",
      "\n",
      "running for subcode  s037120180521\n",
      "Confusion matrix:\n",
      "[[5 5 9]\n",
      " [5 3 8]\n",
      " [7 7 4]]\n",
      "Accuracy: 0.22641509433962265\n",
      "Mean shuffled accuracy (10 runs): 0.330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=None  # none for LinearSVC\n",
    "#clf=sklearn.linear_model.LogisticRegressionCV()\n",
    "\n",
    "for subcode in subcodes:\n",
    "    print('running for subcode ',subcode)\n",
    "    labels,instances=get_data(subcode)\n",
    "    predicted_labels=run_classifier(labels,instances,shuffle=False,clf=clf)\n",
    "    print_metrics(labels,predicted_labels)\n",
    "    # run 10 times to get mean of shuffled accuracy\n",
    "    nruns=10\n",
    "    shuffle_acc=numpy.zeros(nruns)\n",
    "    for r in range(nruns):\n",
    "        predicted_labels=run_classifier(labels,instances,shuffle=True)\n",
    "        shuffle_acc[r]=sklearn.metrics.accuracy_score(labels,predicted_labels)\n",
    "    print('Mean shuffled accuracy (%d runs): %0.3f'%(nruns,numpy.mean(shuffle_acc)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
